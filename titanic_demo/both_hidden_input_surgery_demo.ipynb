{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# hidden num remain unchange"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "old = torch.load('/home/workspace/util/surgery/titanic_demo/runs/May24_08-22-52_1d7a14f7cd78old_network with old input from scratch/oldnetwork_oldinput_from_scratch_bs32.ckpt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# hidden num remain unchange\n",
    "# import os\n",
    "import numpy as np\n",
    "# from torch import optim\n",
    "from pretreat import *\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "training = get_pretreated_training_data()\n",
    "old_input_dict = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'cabine_n', 'IsAlone']\n",
    "new_input_dict = old_input_dict + ['sp', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "loader = get_dataloader(training, new_input_dict, bs=32)\n",
    "new_net = MLP(input_dim = len(new_input_dict), hidden_dims=[40, 50, 100, 100, 100, 100,]).cuda()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "layer = 0\n",
    "w = \"layers.{}.weight\".format(layer)\n",
    "b = \"layers.{}.bias\".format(layer)\n",
    "w1 = old['para'][w]\n",
    "b1 = old['para'][b]\n",
    "\n",
    "inwmap = {}\n",
    "for i, f in enumerate(old['input']):\n",
    "    inwmap[f] = w1[:, i]\n",
    "\n",
    "inbmap = {} # 和hidden node 相关\n",
    "for i in range(w1.shape[0]):\n",
    "    inbmap[i] = b1[i]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "new_net.state_dict()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('layers.0.weight',\n",
       "              tensor([[ 0.1024,  0.0263,  0.0415,  0.1118,  0.2587,  0.1949, -0.1335, -0.1673,\n",
       "                       -0.2020, -0.1017,  0.1835, -0.1012, -0.2724],\n",
       "                      [-0.0717, -0.0484, -0.1261, -0.0118, -0.0865,  0.1870, -0.0985,  0.0696,\n",
       "                        0.1426,  0.0292, -0.2346,  0.2012, -0.2456],\n",
       "                      [ 0.1258, -0.1226,  0.0201,  0.2485, -0.0518,  0.0024, -0.1842, -0.0013,\n",
       "                       -0.1204, -0.1461,  0.0276,  0.0321,  0.1543],\n",
       "                      [ 0.0268, -0.1646,  0.2257, -0.0313,  0.0343,  0.2245,  0.0910, -0.2052,\n",
       "                       -0.0441,  0.1158, -0.2747,  0.1335, -0.2618],\n",
       "                      [-0.0040, -0.2326, -0.2263,  0.0358,  0.1172,  0.1450,  0.1545, -0.0527,\n",
       "                       -0.1835,  0.2368, -0.2382,  0.1838, -0.0470],\n",
       "                      [-0.2068,  0.0014, -0.1838, -0.2324,  0.1587,  0.2762, -0.2317, -0.0708,\n",
       "                        0.1608, -0.2134,  0.1687, -0.1056,  0.1588],\n",
       "                      [ 0.0171, -0.1087,  0.0323, -0.0722,  0.2386, -0.0872,  0.1132, -0.1318,\n",
       "                       -0.2099,  0.2628, -0.2681,  0.0805, -0.1906],\n",
       "                      [-0.1783, -0.0288, -0.1368, -0.1134, -0.0615, -0.1593, -0.1070,  0.2109,\n",
       "                       -0.0328,  0.0215, -0.0769,  0.1741,  0.0770],\n",
       "                      [-0.2658,  0.1362,  0.0615, -0.2439, -0.0511, -0.2707, -0.2151, -0.0363,\n",
       "                       -0.1983,  0.2654, -0.1224,  0.2552, -0.1288],\n",
       "                      [ 0.2459,  0.1939, -0.2337,  0.2217,  0.1744,  0.0940,  0.1471, -0.0516,\n",
       "                        0.2228, -0.0222,  0.0371,  0.0700,  0.2737],\n",
       "                      [-0.0282,  0.0764, -0.1538,  0.2197, -0.1626, -0.0463,  0.0421, -0.0881,\n",
       "                       -0.2377, -0.0960,  0.2752,  0.2019, -0.1353],\n",
       "                      [-0.2368,  0.0653, -0.0835,  0.1257,  0.2500,  0.2242,  0.0317,  0.0146,\n",
       "                       -0.2022, -0.2394, -0.0702, -0.0445, -0.1289],\n",
       "                      [ 0.2228, -0.1352,  0.0853, -0.2263,  0.1609,  0.0702,  0.1984, -0.0196,\n",
       "                        0.0700, -0.2295,  0.2172,  0.0494,  0.0994],\n",
       "                      [ 0.0536,  0.1559, -0.0715, -0.0942,  0.1161,  0.0767, -0.1482,  0.1777,\n",
       "                       -0.0405,  0.2712, -0.0846,  0.1108,  0.1991],\n",
       "                      [-0.2183, -0.2640,  0.1366,  0.1859,  0.1304, -0.1588,  0.1530, -0.2440,\n",
       "                       -0.2505, -0.1292,  0.0850, -0.1353,  0.2010],\n",
       "                      [ 0.0417,  0.2380,  0.0985,  0.1920,  0.1333, -0.0864, -0.2595, -0.1515,\n",
       "                        0.2299,  0.2180, -0.1962, -0.1344,  0.2606],\n",
       "                      [-0.2576, -0.2186,  0.0848, -0.0536, -0.1356,  0.0730, -0.0928,  0.0613,\n",
       "                        0.2587,  0.0138, -0.0249, -0.2067,  0.1418],\n",
       "                      [-0.1009, -0.2031, -0.2594, -0.1495,  0.1542, -0.2058,  0.1695, -0.0174,\n",
       "                       -0.0543,  0.1467,  0.0094,  0.0933,  0.2326],\n",
       "                      [-0.0930,  0.2138, -0.0791, -0.1585, -0.2511, -0.1583, -0.1609, -0.1443,\n",
       "                        0.2024,  0.2360,  0.2246,  0.0377, -0.1923],\n",
       "                      [ 0.0693,  0.2127, -0.2635, -0.2677,  0.2012, -0.2138,  0.2661,  0.1143,\n",
       "                       -0.1467,  0.0843, -0.0078, -0.1650, -0.1097],\n",
       "                      [-0.0357,  0.2676,  0.1269, -0.1000, -0.0692, -0.0765, -0.1702,  0.2144,\n",
       "                        0.1948, -0.0287,  0.1877, -0.2758, -0.1412],\n",
       "                      [-0.1027,  0.0315,  0.1001,  0.1943, -0.1626, -0.1450, -0.0493,  0.1958,\n",
       "                        0.0716, -0.0453,  0.1320,  0.1880, -0.0994],\n",
       "                      [ 0.2050,  0.2485,  0.0096,  0.2730,  0.0865,  0.0381, -0.1802, -0.0219,\n",
       "                       -0.0596,  0.1367,  0.0018,  0.0456,  0.0236],\n",
       "                      [ 0.2771, -0.0054, -0.0164, -0.0016, -0.1485,  0.1450,  0.1443,  0.1276,\n",
       "                        0.0471,  0.0568,  0.2490,  0.2198,  0.2745],\n",
       "                      [ 0.1548, -0.2246, -0.2674, -0.1765,  0.0569, -0.2538, -0.2765,  0.1249,\n",
       "                        0.0815, -0.0723,  0.2563,  0.2424,  0.2588],\n",
       "                      [ 0.1207,  0.1544,  0.1827, -0.1937,  0.2550, -0.0742, -0.2507,  0.1183,\n",
       "                        0.2492,  0.0573, -0.0184,  0.0190, -0.1923],\n",
       "                      [-0.1329, -0.0392,  0.1370,  0.2550,  0.1181,  0.1569, -0.0653, -0.2340,\n",
       "                       -0.0293,  0.2384,  0.1093, -0.1869, -0.1721],\n",
       "                      [ 0.2117,  0.0689, -0.0243, -0.1445,  0.1531,  0.0056,  0.2607,  0.0026,\n",
       "                       -0.1807, -0.2480,  0.1967,  0.0754, -0.1825],\n",
       "                      [ 0.2541,  0.0187,  0.0623,  0.2058, -0.1930, -0.1748, -0.1769, -0.0589,\n",
       "                       -0.0634,  0.1378, -0.0867, -0.1609, -0.0532],\n",
       "                      [-0.2628,  0.1236,  0.1117, -0.0212,  0.2606, -0.1694,  0.2273, -0.1909,\n",
       "                        0.1526,  0.2174,  0.0916,  0.2206,  0.0544],\n",
       "                      [-0.1126, -0.2117, -0.0177, -0.1905, -0.1425, -0.1248, -0.0496, -0.0534,\n",
       "                       -0.1470, -0.1346, -0.0566,  0.0810,  0.1169],\n",
       "                      [ 0.1867, -0.2143, -0.2319,  0.1929, -0.1745, -0.1198, -0.1439,  0.1018,\n",
       "                       -0.2058, -0.0788,  0.0949, -0.1747, -0.2079],\n",
       "                      [-0.1614, -0.1474,  0.0534, -0.2487, -0.1148, -0.2347,  0.2136,  0.1586,\n",
       "                        0.2422,  0.1927, -0.2677, -0.1595, -0.2176],\n",
       "                      [-0.1449, -0.0460, -0.1397, -0.1604,  0.1860, -0.1845, -0.1924, -0.0047,\n",
       "                       -0.0213,  0.1559,  0.2767,  0.0556,  0.0739],\n",
       "                      [-0.2658,  0.1934, -0.1936, -0.2413,  0.1505,  0.1755,  0.1809,  0.2540,\n",
       "                       -0.1192, -0.0858, -0.2170,  0.2453,  0.2391],\n",
       "                      [ 0.2394, -0.2126, -0.1999,  0.1512,  0.0775, -0.0953, -0.0686,  0.0489,\n",
       "                       -0.1410,  0.0986, -0.0016, -0.2031, -0.2768],\n",
       "                      [-0.0253, -0.1749, -0.0582, -0.2770, -0.2180, -0.1077,  0.1406,  0.1198,\n",
       "                       -0.1825,  0.2493,  0.1637,  0.1981, -0.1594],\n",
       "                      [ 0.1870,  0.2485,  0.1156, -0.0846,  0.1017,  0.1262, -0.0515, -0.2683,\n",
       "                        0.0884, -0.1648, -0.2412,  0.2761,  0.0287],\n",
       "                      [-0.1983, -0.1855, -0.1783, -0.0003,  0.0884, -0.1259,  0.2184, -0.1368,\n",
       "                       -0.0828, -0.2659,  0.0652,  0.1763, -0.0273],\n",
       "                      [-0.1204, -0.2399, -0.0963, -0.2435,  0.1574, -0.2511, -0.1192, -0.1423,\n",
       "                       -0.1771,  0.0794,  0.2236, -0.0832, -0.0349]], device='cuda:0')),\n",
       "             ('layers.0.bias',\n",
       "              tensor([-0.1592,  0.1099,  0.1859,  0.1903,  0.2632, -0.1802,  0.0652, -0.1901,\n",
       "                       0.0341,  0.0590, -0.0273, -0.1749,  0.2728, -0.1604, -0.1584,  0.2620,\n",
       "                       0.1883, -0.1378,  0.0331,  0.2486, -0.0999,  0.2423,  0.0890, -0.2092,\n",
       "                      -0.0371,  0.1602, -0.2663, -0.0077, -0.0238, -0.1641, -0.0626,  0.1790,\n",
       "                       0.1438, -0.0508, -0.0285,  0.1328, -0.1917, -0.1870, -0.2593, -0.1738],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.2.weight',\n",
       "              tensor([[ 0.1463,  0.1317, -0.0126,  ...,  0.0468, -0.1309, -0.0007],\n",
       "                      [ 0.0110,  0.0017, -0.1121,  ..., -0.1321, -0.0949, -0.0561],\n",
       "                      [-0.1322, -0.0123,  0.0643,  ...,  0.0521,  0.0198, -0.1009],\n",
       "                      ...,\n",
       "                      [ 0.0216, -0.1045, -0.0460,  ...,  0.1248,  0.1421,  0.1133],\n",
       "                      [ 0.1020, -0.1135,  0.0393,  ...,  0.1343,  0.1452, -0.0563],\n",
       "                      [ 0.0766, -0.1417,  0.0923,  ...,  0.0097,  0.1404, -0.0767]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.2.bias',\n",
       "              tensor([-0.0757,  0.0868, -0.0703, -0.0946,  0.0649,  0.1029,  0.1480,  0.0030,\n",
       "                       0.1165,  0.1066,  0.0373, -0.0980, -0.0240,  0.0091,  0.0736, -0.0906,\n",
       "                      -0.1312, -0.0590, -0.0246,  0.0191,  0.0169, -0.0375, -0.1391,  0.0952,\n",
       "                       0.1553, -0.0823, -0.1055,  0.1049, -0.1481,  0.0346,  0.0527, -0.0124,\n",
       "                      -0.0289,  0.1040,  0.0061, -0.0778,  0.0319, -0.0037,  0.0316,  0.0154,\n",
       "                      -0.0350,  0.1099,  0.1204,  0.0118,  0.1072, -0.1020, -0.1174, -0.0966,\n",
       "                       0.0645, -0.1171], device='cuda:0')),\n",
       "             ('layers.4.weight',\n",
       "              tensor([[-0.1301,  0.0996,  0.0159,  ..., -0.1250,  0.0443,  0.1328],\n",
       "                      [-0.0173, -0.0703,  0.0851,  ..., -0.1279,  0.0075,  0.1026],\n",
       "                      [-0.0760, -0.0215,  0.0994,  ...,  0.0500, -0.0432, -0.0279],\n",
       "                      ...,\n",
       "                      [-0.1033, -0.0478,  0.1271,  ..., -0.1184,  0.0107, -0.0162],\n",
       "                      [-0.1041, -0.0487, -0.1036,  ...,  0.0668, -0.0600, -0.0540],\n",
       "                      [ 0.1315,  0.1294,  0.0683,  ...,  0.1240,  0.0586,  0.0914]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.4.bias',\n",
       "              tensor([ 1.0631e-03, -1.0411e-01, -1.0104e-01, -1.3090e-01,  1.3119e-01,\n",
       "                      -1.0123e-01,  7.8954e-02,  1.0742e-01,  4.6445e-02,  1.2758e-01,\n",
       "                       1.3381e-01,  9.2348e-02,  1.2413e-01,  1.2736e-02, -1.0076e-01,\n",
       "                      -4.3893e-02, -1.2283e-01, -1.1330e-01, -1.6892e-02, -1.1932e-01,\n",
       "                      -2.6462e-02, -1.0808e-01,  9.9091e-02,  1.3847e-01, -7.5589e-02,\n",
       "                      -5.8494e-02,  1.0002e-01, -3.5650e-02, -1.2331e-01, -1.3416e-02,\n",
       "                      -1.0316e-01, -1.0642e-01, -5.4691e-02,  1.1553e-02,  1.0256e-01,\n",
       "                      -3.9475e-02, -1.2626e-01, -8.6269e-02,  9.3877e-02,  5.3759e-02,\n",
       "                       9.4642e-02, -9.0102e-02,  1.0562e-01,  1.5024e-02,  7.8523e-02,\n",
       "                      -2.9180e-02, -2.0088e-02, -1.3224e-01, -3.4650e-02, -9.3245e-02,\n",
       "                       1.2427e-01, -1.9539e-02,  6.0211e-02,  6.4170e-02, -6.4391e-02,\n",
       "                       1.1381e-01, -1.5856e-02, -8.3530e-02, -1.2068e-01,  4.6653e-02,\n",
       "                      -1.3843e-01,  8.6363e-02, -1.1453e-01, -8.4394e-02, -9.8107e-02,\n",
       "                       5.3708e-02,  3.6195e-02, -5.9932e-02, -5.6775e-02,  5.7514e-02,\n",
       "                      -1.0432e-01,  1.3085e-01, -4.7100e-02,  3.1103e-02, -6.6162e-02,\n",
       "                       1.0536e-01,  3.7867e-02, -7.6955e-02, -2.5066e-02, -3.3434e-02,\n",
       "                      -9.7942e-02,  2.0062e-06, -1.4890e-02,  1.1142e-01, -6.6301e-02,\n",
       "                      -3.4179e-02,  3.0933e-02,  9.5326e-02, -1.0627e-02, -1.9270e-02,\n",
       "                      -8.2020e-02, -1.1180e-01,  1.1300e-01, -1.1021e-02,  1.2863e-01,\n",
       "                      -1.2700e-01,  9.2264e-02,  7.8382e-02, -1.3552e-01,  5.5607e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.6.weight',\n",
       "              tensor([[-0.0419,  0.0050, -0.0645,  ...,  0.0154,  0.0981, -0.0599],\n",
       "                      [ 0.0854, -0.0847, -0.0244,  ..., -0.0809, -0.0807, -0.0962],\n",
       "                      [ 0.0685, -0.0613, -0.0973,  ..., -0.0298,  0.0443, -0.0059],\n",
       "                      ...,\n",
       "                      [ 0.0772,  0.0100,  0.0819,  ..., -0.0265,  0.0447,  0.0213],\n",
       "                      [-0.0115, -0.0663, -0.0894,  ...,  0.0720, -0.0064, -0.0033],\n",
       "                      [-0.0743, -0.0083, -0.0015,  ..., -0.0216, -0.0881, -0.0497]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.6.bias',\n",
       "              tensor([-0.0956, -0.0994, -0.0524,  0.0303,  0.0453,  0.0911, -0.0298,  0.0468,\n",
       "                       0.0286,  0.0392,  0.0480, -0.0959, -0.0254,  0.0943, -0.0123, -0.0662,\n",
       "                      -0.0098,  0.0384,  0.0926, -0.0223, -0.0409,  0.0279, -0.0978,  0.0177,\n",
       "                       0.0109, -0.0882,  0.0914,  0.0466, -0.0695,  0.0356, -0.0623,  0.0673,\n",
       "                       0.0446, -0.0881, -0.0784,  0.0475, -0.0825, -0.0969,  0.0458, -0.0375,\n",
       "                       0.0171, -0.0209, -0.0610, -0.0240, -0.0596, -0.0993,  0.0509,  0.0202,\n",
       "                       0.0146, -0.0886,  0.0536,  0.0298,  0.0679, -0.0103,  0.0485, -0.0325,\n",
       "                      -0.0882,  0.0935,  0.0703, -0.0079, -0.0962,  0.0007,  0.0666, -0.0977,\n",
       "                       0.0594, -0.0954, -0.0247, -0.0230,  0.0284,  0.0749, -0.0698,  0.0647,\n",
       "                      -0.0941, -0.0500,  0.0503, -0.0886,  0.0780, -0.0499, -0.0459, -0.0068,\n",
       "                      -0.0134,  0.0948,  0.0007, -0.0191, -0.0440, -0.0212,  0.0388, -0.0132,\n",
       "                      -0.0938, -0.0983, -0.0794, -0.0675,  0.0445, -0.0269, -0.0336, -0.0298,\n",
       "                      -0.0446,  0.0485, -0.0730, -0.0834], device='cuda:0')),\n",
       "             ('layers.8.weight',\n",
       "              tensor([[-0.0247, -0.0610, -0.0767,  ..., -0.0314,  0.0905,  0.0834],\n",
       "                      [-0.0786,  0.0479, -0.0510,  ..., -0.0706,  0.0511, -0.0721],\n",
       "                      [ 0.0343,  0.0592, -0.0437,  ..., -0.0593, -0.0244,  0.0563],\n",
       "                      ...,\n",
       "                      [ 0.0363, -0.0686, -0.0176,  ..., -0.0439, -0.0434,  0.0930],\n",
       "                      [-0.0597,  0.0398,  0.0856,  ...,  0.0167, -0.0760,  0.0452],\n",
       "                      [ 0.0603, -0.0899,  0.0652,  ...,  0.0142,  0.0005, -0.0726]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.8.bias',\n",
       "              tensor([-0.0872, -0.0925, -0.0107,  0.0419,  0.0589, -0.0697,  0.0210, -0.0996,\n",
       "                      -0.0843,  0.0558, -0.0307, -0.0227, -0.0904, -0.0881,  0.0119, -0.0023,\n",
       "                       0.0231,  0.0680, -0.0459,  0.0797, -0.0178, -0.0557,  0.0435,  0.0999,\n",
       "                       0.0392, -0.0791,  0.0732,  0.0439, -0.0582,  0.0293,  0.0052, -0.0095,\n",
       "                      -0.0216, -0.0913,  0.0907,  0.0953, -0.0771, -0.0265,  0.0781, -0.0374,\n",
       "                       0.0316, -0.0156,  0.0371, -0.0632, -0.0113, -0.0897,  0.0383, -0.0701,\n",
       "                      -0.0905,  0.0455,  0.0914,  0.0751,  0.0655, -0.0425,  0.0339, -0.0965,\n",
       "                       0.0604,  0.0967,  0.0669, -0.0077, -0.0884, -0.0694,  0.0326,  0.0780,\n",
       "                       0.0376,  0.0970,  0.0570, -0.0591,  0.0399,  0.0154, -0.0230,  0.0216,\n",
       "                      -0.0791, -0.0076,  0.0959, -0.0265, -0.0814,  0.0658, -0.0256, -0.0990,\n",
       "                       0.0522, -0.0164,  0.0197,  0.0638,  0.0493,  0.0124, -0.0056,  0.0949,\n",
       "                      -0.0929, -0.0370,  0.0967,  0.0935,  0.0115, -0.0312,  0.0937, -0.0975,\n",
       "                      -0.0268, -0.0641, -0.0455, -0.0932], device='cuda:0')),\n",
       "             ('layers.10.weight',\n",
       "              tensor([[-0.0707,  0.0407,  0.0446,  ...,  0.0514, -0.0441, -0.0132],\n",
       "                      [-0.0819,  0.0875, -0.0496,  ...,  0.0046, -0.0801,  0.0753],\n",
       "                      [-0.0504,  0.0018,  0.0179,  ...,  0.0408,  0.0581,  0.0667],\n",
       "                      ...,\n",
       "                      [ 0.0516,  0.0723, -0.0199,  ..., -0.0323, -0.0355,  0.0911],\n",
       "                      [-0.0691, -0.0561,  0.0708,  ..., -0.0795,  0.0052,  0.0593],\n",
       "                      [ 0.0765, -0.0513,  0.0523,  ...,  0.0117, -0.0137,  0.0712]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.10.bias',\n",
       "              tensor([-0.0773, -0.0115, -0.0196,  0.0929,  0.0760, -0.0266,  0.0528,  0.0679,\n",
       "                      -0.0703, -0.0138,  0.0343, -0.0222, -0.0115, -0.0585,  0.0481,  0.0356,\n",
       "                       0.0722,  0.0383, -0.0942,  0.0885,  0.0564, -0.0863, -0.0251,  0.0432,\n",
       "                       0.0057,  0.0855, -0.0576,  0.0796, -0.0591,  0.0909, -0.0157, -0.0576,\n",
       "                       0.0999,  0.0471, -0.0604,  0.0827,  0.0976, -0.0040,  0.0157,  0.0852,\n",
       "                      -0.0157,  0.0334, -0.0546, -0.0960, -0.0673, -0.0853, -0.0070, -0.0604,\n",
       "                       0.0833,  0.0701, -0.0493, -0.0556,  0.0243, -0.0200, -0.0151, -0.0374,\n",
       "                      -0.0027, -0.0620, -0.0210, -0.0146,  0.0528, -0.0800,  0.0047,  0.0351,\n",
       "                       0.0828,  0.0241,  0.0197, -0.0576, -0.0101,  0.0809, -0.0817,  0.0032,\n",
       "                      -0.0552, -0.0057,  0.0348,  0.0826,  0.0273, -0.0706,  0.0172,  0.0147,\n",
       "                      -0.0985,  0.0418, -0.0273, -0.0755, -0.0322, -0.0835,  0.0656, -0.0932,\n",
       "                       0.0098, -0.0609, -0.0698, -0.0174,  0.0878,  0.0704,  0.0650, -0.0350,\n",
       "                       0.0612,  0.0730, -0.0961,  0.0112], device='cuda:0')),\n",
       "             ('layers.12.weight',\n",
       "              tensor([[-6.7617e-02, -3.6054e-02, -9.2701e-02,  1.9195e-02, -9.2513e-02,\n",
       "                        4.6658e-03, -1.3552e-02,  4.0789e-02, -1.9166e-02,  9.3451e-02,\n",
       "                       -9.7229e-02, -4.5718e-02, -4.4321e-02,  5.0517e-03, -1.2273e-02,\n",
       "                        8.2521e-02, -8.7046e-02,  1.4206e-02,  7.5485e-02, -8.6243e-03,\n",
       "                       -6.0272e-02,  9.2683e-02, -4.2335e-03,  6.5602e-02,  3.9890e-02,\n",
       "                        4.8133e-02,  8.7949e-02,  5.4746e-02, -2.7289e-02, -7.1003e-02,\n",
       "                       -8.2512e-02,  5.3396e-03, -4.9579e-02, -1.8902e-02,  1.8701e-02,\n",
       "                        3.0499e-02, -2.2190e-02, -1.3810e-02,  9.8037e-02,  5.8633e-02,\n",
       "                        9.9950e-02,  2.8244e-02,  3.9607e-02,  6.1114e-02,  6.4406e-03,\n",
       "                        4.6192e-02, -7.9076e-02, -5.4862e-03, -9.6243e-02, -1.6683e-02,\n",
       "                       -3.4859e-02,  1.6757e-02,  7.9172e-02,  9.6352e-02,  3.3717e-02,\n",
       "                        4.3971e-02,  1.7762e-02, -6.8953e-02, -1.5545e-02, -8.8685e-02,\n",
       "                        8.3395e-02, -6.7024e-02,  1.9964e-02, -9.3291e-02, -9.5049e-02,\n",
       "                       -8.2473e-02, -5.1484e-02, -1.6068e-02, -5.0964e-02, -6.9875e-02,\n",
       "                       -6.3769e-02, -8.2552e-02,  4.4021e-02,  7.7629e-03,  5.0358e-02,\n",
       "                        8.1518e-02,  9.5720e-03, -5.4181e-02, -4.2122e-02, -1.3953e-02,\n",
       "                        9.1975e-02,  7.5135e-03, -7.6363e-02, -9.9067e-03, -5.6535e-02,\n",
       "                       -1.5631e-03, -3.4841e-02,  7.3206e-02, -4.3022e-02,  7.8019e-02,\n",
       "                       -6.0366e-02,  3.6162e-02, -6.6445e-02, -1.8729e-02,  5.5304e-02,\n",
       "                        9.3044e-02, -4.5495e-02, -2.2268e-02, -8.8247e-02, -5.2932e-02],\n",
       "                      [ 6.2864e-02,  4.4795e-02,  5.6353e-02, -3.3704e-02,  9.5149e-02,\n",
       "                       -3.8125e-03,  9.2863e-03, -5.9529e-02,  6.7471e-02,  3.4942e-02,\n",
       "                        7.0555e-02, -3.7996e-02, -1.6525e-03, -9.1421e-02,  2.5219e-02,\n",
       "                       -2.2643e-02, -6.2942e-02, -2.8410e-02, -3.6608e-02,  7.7370e-02,\n",
       "                       -8.1542e-02, -5.1368e-02, -7.6538e-02, -7.0934e-02,  3.2674e-02,\n",
       "                       -9.6252e-02, -1.2446e-02, -5.0771e-02,  9.7225e-02,  5.5191e-02,\n",
       "                       -3.9780e-02, -2.6868e-02,  6.3925e-02, -2.3847e-02,  3.9713e-02,\n",
       "                        2.2924e-02, -1.5651e-02,  4.2689e-02,  9.5249e-02, -8.2321e-02,\n",
       "                        7.8815e-02,  5.0890e-02, -5.8952e-02,  8.6949e-03,  5.8613e-02,\n",
       "                        9.9135e-02,  1.3005e-02,  6.7184e-02,  8.9904e-02, -3.0069e-02,\n",
       "                       -2.8907e-03, -8.4609e-02,  6.1757e-02, -3.8194e-02, -2.2595e-02,\n",
       "                        9.1947e-02,  6.3522e-02,  7.6728e-03,  2.7643e-02,  9.2170e-02,\n",
       "                       -9.8169e-02,  5.3170e-02, -5.4712e-02, -6.3795e-02, -5.4015e-02,\n",
       "                       -7.0888e-02, -9.9678e-02,  7.3345e-02, -7.6293e-03,  6.9004e-02,\n",
       "                       -1.1384e-02, -7.4282e-02,  8.1540e-02,  8.8969e-02, -2.9105e-02,\n",
       "                        5.3048e-06, -2.1490e-02,  5.0932e-02, -5.4946e-02, -1.6662e-02,\n",
       "                       -5.4209e-02,  6.8184e-02, -9.8380e-02, -5.2734e-02,  4.7882e-03,\n",
       "                        9.3229e-03, -1.4248e-02, -2.1771e-02, -1.0251e-03, -6.8971e-02,\n",
       "                        5.9368e-02,  5.1491e-02, -7.8939e-02,  4.4511e-02,  8.4037e-02,\n",
       "                        8.1659e-02, -4.5088e-03,  2.8522e-02,  8.6874e-02, -4.5514e-02]],\n",
       "                     device='cuda:0')),\n",
       "             ('layers.12.bias', tensor([0.0614, 0.0324], device='cuda:0'))])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# 增加了输入 和中间层, 对于多出来的进行0初始化, 假设所有多出来的node都在原来hidden的下面同一侧\n",
    "for i, (name, g) in enumerate(new_net.named_parameters()):\n",
    "    old_g = old['para'][name].data\n",
    "    if old_g.shape != g.shape:\n",
    "        if i == 1:\n",
    "            # new_g = torch.zeros_like(g)\n",
    "            # new_g = torch.ones_like(g) * (10 **(-40))\n",
    "            for hidden_n, b in inbmap.items():\n",
    "                new_g[hidden_n] = b\n",
    "        elif i == 0:\n",
    "            # new_g = torch.zeros_like(g) # 最开始的初始化方式是0初始化所有新权重, 发现因为ReLU的关系, 训练后都为0\n",
    "            # new_g = torch.ones_like(g) * (10 **(-40)) #  然后使用很小的权重初始化, 训练后不为0了, 但是查看了一下权重, 感觉还是有点问题, 很多都是10**-40左右. \n",
    "            for j, f in enumerate(new_input_dict):\n",
    "                if f in inwmap.keys():\n",
    "                    old_w = inwmap[f]\n",
    "                    new_g[:old_w.shape[0], j] = old_w\n",
    "        elif i == 2:\n",
    "            new_g = g.clone().detach() # 这里是忘记改了\n",
    "            new_g[:, :old_g.shape[1]] = old_g\n",
    "        else:\n",
    "            assert False\n",
    "        g.data = new_g\n",
    "    else:\n",
    "        # print(name, g.shape)\n",
    "        g.data = old['para'][name].data\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 增加了输入 和中间层, 对于多出来的进行0初始化, 假设所有多出来的node都在原来hidden的下面同一侧\n",
    "for i, (name, g) in enumerate(new_net.named_parameters()):\n",
    "    old_g = old['para'][name].data\n",
    "    if old_g.shape != g.shape:\n",
    "        if i == 1:\n",
    "            new_g = g.data * (10**(-20))\n",
    "            for hidden_n, b in inbmap.items():\n",
    "                new_g[hidden_n] = b\n",
    "        elif i == 0:\n",
    "            new_g = g.data * (10**(-20))\n",
    "            for j, f in enumerate(new_input_dict):\n",
    "                if f in inwmap.keys():\n",
    "                    old_w = inwmap[f]\n",
    "                    new_g[:old_w.shape[0], j] = old_w\n",
    "        elif i == 2:\n",
    "            new_g = torch.zeros_like(g)\n",
    "            new_g[:, :old_g.shape[1]] = old_g\n",
    "        else:\n",
    "            assert False\n",
    "        g.data = new_g\n",
    "    else:\n",
    "        # print(name, g.shape)\n",
    "        g.data = old['para'][name].data\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# get surgery之后最初始的acc\n",
    "sum_acc = 0\n",
    "for x, y in loader:\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    outputs=new_net(x)\n",
    "    _,id=torch.max(outputs.data,1)\n",
    "    acc=torch.sum(id==y.data)\n",
    "    sum_acc += acc.item() \n",
    "print(sum_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "752\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "lr = 0.001\n",
    "epoches = 2000 \n",
    "comment = 'hidden_add_new_net with new input Using Surgery'\n",
    "model_name = 'hidden_add_newnetwork_newinput_usingSurgery.ckpt'\n",
    "input_dic = new_input_dict\n",
    "acc_cur, loss_cur = train(new_net, loader, comment, model_name, input_dic, )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:0, loss:13.298031389713287, acc:0.8383838383838383\n",
      "epoch:500, loss:11.919799119234085, acc:0.8877665544332211\n",
      "epoch:1000, loss:12.139749348163605, acc:0.8810325476992144\n",
      "epoch:1500, loss:12.01339527964592, acc:0.8855218855218855\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "new_net.state_dict()['layers.0.weight'][25:]\n",
    "# new_net.state_dict()['layers.0.bias']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-6.0361e-41, -4.0102e-16,  1.7307e-41, -4.2621e-40, -5.0089e-22,\n",
       "          4.8372e-40, -1.1254e-40,  1.9111e-41,  2.2774e-41, -1.0781e-40,\n",
       "          4.6663e-40,  1.9149e-40, -8.8530e-41],\n",
       "        [-5.1151e-17, -3.6522e-05,  4.4056e-37,  2.6964e-37, -1.9355e-06,\n",
       "         -6.9483e-41, -3.5926e-41,  4.8288e-37, -5.8953e-42,  5.2027e-38,\n",
       "          6.9370e-41,  6.5057e-41,  2.2735e-38],\n",
       "        [-4.3567e-31, -4.2704e-04, -3.8406e-30,  3.7370e-30, -1.2069e-05,\n",
       "          3.0258e-41, -5.2843e-41, -4.7967e-30, -2.9663e-31, -7.7387e-33,\n",
       "          2.4121e-41, -1.1592e-40, -2.4645e-31],\n",
       "        [-1.4264e-15, -2.8356e-04,  1.3576e-28,  3.4887e-29, -2.0630e-07,\n",
       "          8.0119e-41, -5.5197e-42,  1.2111e-28,  5.9326e-30,  3.8508e-31,\n",
       "         -6.6553e-41, -1.9503e-41,  6.7608e-30],\n",
       "        [-3.0436e-42, -5.3058e-32,  1.5879e-40, -5.4605e-40,  6.0636e-41,\n",
       "         -5.7403e-40,  1.1074e-40,  1.1032e-40,  9.2772e-41,  8.3531e-42,\n",
       "          1.0157e-41,  2.9613e-40, -3.3410e-41],\n",
       "        [-1.9827e-15, -1.0110e-04,  2.4766e-38,  5.1807e-38, -1.4625e-04,\n",
       "         -8.2768e-41, -7.4524e-41,  4.0690e-32, -4.6321e-41,  4.5743e-38,\n",
       "          2.2146e-41, -5.3976e-40, -2.2976e-38],\n",
       "        [ 1.0373e-23, -1.2184e-06, -7.2331e-27,  1.0283e-26, -1.4099e-24,\n",
       "         -2.1398e-24, -2.6473e-24, -7.5151e-27,  2.9217e-24, -2.1376e-24,\n",
       "          1.1932e-26, -5.3862e-30, -2.6232e-24],\n",
       "        [-7.5533e-17, -4.2071e-05,  9.6171e-41, -2.3555e-40, -5.2420e-04,\n",
       "         -4.2845e-40, -1.7928e-40,  1.0986e-40, -8.5458e-41,  1.7290e-40,\n",
       "          1.5408e-40,  5.6629e-40,  4.5560e-41],\n",
       "        [ 3.2375e-02, -1.5592e-02,  8.7636e-03, -5.8216e-04, -1.9111e-02,\n",
       "         -4.6745e-02,  2.8643e-04,  9.3575e-03, -1.2443e-02,  4.8402e-03,\n",
       "          2.0863e-03,  8.5086e-17, -5.8274e-03],\n",
       "        [ 8.7539e-03, -1.9567e-02,  4.8449e-02,  1.7531e-02,  5.8161e-03,\n",
       "         -3.3384e-02, -4.2460e-02,  3.3142e-02, -3.7280e-03, -7.2308e-03,\n",
       "         -6.0915e-02,  3.9229e-02,  1.2023e-02],\n",
       "        [ 4.8604e-32, -8.0436e-09,  3.3373e-31, -4.0358e-31, -1.4811e-11,\n",
       "          8.7430e-41, -6.3287e-41,  4.1711e-31,  2.7251e-32,  2.3515e-33,\n",
       "         -5.8836e-41, -1.5640e-40,  2.9108e-32],\n",
       "        [ 1.1184e-03, -3.7560e-03, -1.1347e-05,  1.2260e-04, -3.2761e-02,\n",
       "         -2.9041e-04, -1.4859e-03,  1.2730e-03,  4.7343e-04, -2.8403e-03,\n",
       "          1.5947e-04,  6.9919e-41, -5.5707e-04],\n",
       "        [-2.7354e-04, -1.6571e-02, -1.4044e-09, -4.2850e-39, -1.4163e-02,\n",
       "          3.1397e-24, -2.3029e-22, -2.0752e-09, -9.0877e-10,  9.2821e-24,\n",
       "         -1.1089e-09,  1.0543e-38, -2.2004e-22],\n",
       "        [-2.1581e-03, -2.1281e-02, -1.6911e-03, -2.9068e-06, -1.0140e-02,\n",
       "         -4.2269e-21, -2.0117e-12, -3.0343e-03,  1.8090e-11, -1.8759e-06,\n",
       "         -1.2966e-14, -3.5173e-43, -2.2226e-06],\n",
       "        [-3.7486e-02, -3.2686e-02, -3.1789e-02, -3.0280e-02,  4.0521e-03,\n",
       "         -5.6502e-02,  2.0640e-02, -3.3548e-02, -1.5364e-02, -5.8593e-02,\n",
       "          1.0893e-02, -1.3057e-03, -3.7129e-02]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "surgery['para']['layers.0.weight'][20:]\n",
    "# surgery['para']['layers.0.bias']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-7.5485e-03, -2.1980e-02, -2.7966e-05,  1.1425e-04, -2.0070e-02,\n",
       "          4.0945e-09, -3.8096e-04, -1.1435e-03, -7.6633e-04, -2.3985e-07,\n",
       "          1.8934e-07,  1.4813e-09, -1.0805e-03],\n",
       "        [-9.6301e-01,  4.3007e-02, -1.3960e+00,  5.3394e-01,  1.8821e-01,\n",
       "          3.9834e-01, -3.7659e-01, -2.6922e-01,  4.4095e-01, -5.6407e-01,\n",
       "         -1.4727e-01, -1.7821e-01,  8.5678e-02],\n",
       "        [-7.0375e-08, -9.4626e-03,  3.2083e-12, -4.3046e-14, -1.4371e-02,\n",
       "         -2.1414e-07, -1.1120e-06,  4.0246e-10, -3.9200e-09,  2.3470e-09,\n",
       "          5.8830e-13, -6.7900e-41, -7.5925e-07],\n",
       "        [-9.1132e-01, -1.6379e-01,  3.6612e-01, -1.3511e+00,  3.5460e-01,\n",
       "          7.5859e-01, -3.9762e-01, -2.5670e-01,  2.7064e-01, -6.2972e-01,\n",
       "          5.6717e-02,  4.3588e-01, -5.4023e-01],\n",
       "        [-3.2494e-01, -1.3964e-01, -1.2276e+00,  4.2912e-01,  3.8093e-01,\n",
       "         -3.0529e-01,  3.5404e-02, -1.8604e-01, -4.7902e-01,  3.2775e-01,\n",
       "          1.7182e-01,  5.7916e-03, -1.1977e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tftorch': conda)"
  },
  "interpreter": {
   "hash": "3242c50314a9a68f934114b03bfda27d4d4439c8399dcbb46cdc3239617c61c1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}