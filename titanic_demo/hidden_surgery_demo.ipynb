{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# hidden num remain unchange, Using Surgery\n",
    "import torch\n",
    "old = torch.load('/home/workspace/util/surgery/titanic_demo/runs/May24_08-22-52_1d7a14f7cd78old_network with old input from scratch/oldnetwork_oldinput_from_scratch_bs32.ckpt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from pretreat import *\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "training = get_pretreated_training_data()\n",
    "old_input_dict = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'cabine_n', 'IsAlone']\n",
    "loader = get_dataloader(training, old_input_dict, bs=32)\n",
    "model = MLP(input_dim = len(old_input_dict), hidden_dims=[40, 50, 100, 100, 100, 100,]).cuda()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for i, (name, g) in enumerate(model.named_parameters()):\n",
    "    if name == 'layers.0.weight':\n",
    "        print(name, g[20:30, :2])\n",
    "    if name == 'layers.0.bias':\n",
    "        print(name, g[20:30])\n",
    "    # print(name, g[:2]) if i%2 else print(name, g[:2, :2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layers.0.weight tensor([[ 0.1539,  0.0256],\n",
      "        [-0.3500,  0.2779],\n",
      "        [-0.0202,  0.1378],\n",
      "        [ 0.1163, -0.0836],\n",
      "        [-0.2597, -0.2726],\n",
      "        [-0.1182, -0.3295],\n",
      "        [ 0.3205, -0.1218],\n",
      "        [-0.1202,  0.0017],\n",
      "        [-0.3518,  0.2374],\n",
      "        [-0.1666, -0.1704]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "layers.0.bias tensor([ 0.1186, -0.0353,  0.1577,  0.3102,  0.1784,  0.3436,  0.1144,  0.0822,\n",
      "        -0.1515, -0.0894], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 只增加中间层, 那么只需要对多出来的进行0初始化就好了, \n",
    "for i, (name, g) in enumerate(model.named_parameters()):\n",
    "    old_g = old['para'][name].data\n",
    "    g.data = g.data.zero_()\n",
    "    if i%2:\n",
    "        d = old_g.shape\n",
    "        g.data[:oi] = old_g\n",
    "    else:\n",
    "        oi, oo = old_g.shape\n",
    "        g.data[:oi,:oo] = old_g"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "for i, (name, g) in enumerate(model.named_parameters()):\n",
    "    if name == 'layers.0.weight':\n",
    "        print(name, g[20:30, :2])\n",
    "    if name == 'layers.0.bias':\n",
    "        print(name, g[20:30])\n",
    "    # print(name, g[:2]) if i%2 else print(name, g[:2, :2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layers.0.weight tensor([[-4.5212e-07, -1.1475e-02],\n",
      "        [-7.5477e-01,  2.4377e-02],\n",
      "        [ 7.2729e-41, -2.0507e-10],\n",
      "        [-8.0097e-01, -1.7311e-01],\n",
      "        [-3.5086e-01, -1.5174e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "layers.0.bias tensor([-3.4280e-13, -4.6570e-01, -3.5227e-41,  8.5131e-02,  2.4277e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# get surgery之后最初始的acc\n",
    "sum_acc = 0\n",
    "for x, y in loader:\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    outputs=model(x)\n",
    "    _,id=torch.max(outputs.data,1)\n",
    "    acc=torch.sum(id==y.data)\n",
    "    sum_acc += acc.item()    \n",
    "print(sum_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "752\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "lr = 0.001\n",
    "epoches = 2000 \n",
    "comment = 'new_network with old input Using Surgery'\n",
    "model_name = 'newnetwork_oldinput_usingSurgery.ckpt'\n",
    "input_dic = old_input_dict\n",
    "acc_cur, loss_cur = train(model, loader, comment, model_name, input_dic, )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:0, loss:13.409809857606888, acc:0.8338945005611672\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tftorch': conda)"
  },
  "interpreter": {
   "hash": "3242c50314a9a68f934114b03bfda27d4d4439c8399dcbb46cdc3239617c61c1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}