{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# >> tensorboard --logdir=./tensorboard\n",
    "'''\n",
    "Do Surgery, test Surgery\n",
    "and keep train. \n",
    "'''\n",
    "import json\n",
    "import gym\n",
    "import datetime\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class Json_Parser:\n",
    "    def __init__(self, file_name):\n",
    "        with open(file_name) as json_file:\n",
    "            self.json_data = json.load(json_file)\n",
    "\n",
    "    def load_parser(self):\n",
    "        return self.json_data\n",
    "\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.parser = Json_Parser(\"config.json\")\n",
    "        h = self.parser.load_parser()['agent']['hidden_unit']\n",
    "        self.fc1 = nn.Linear(8, h)\n",
    "        self.fc2 = nn.Linear(h, h)\n",
    "        self.fc3 = nn.Linear(h, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        acti = self.parser.load_parser()['agent']['activation']\n",
    "        if acti == \"relu\":\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "        elif acti == \"sigmoid\":\n",
    "            x = torch.sigmoid(self.fc1(x))\n",
    "            x = torch.sigmoid(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "        elif acti == \"softmax\":\n",
    "            x = F.softmax(self.fc1(x), dim=0)\n",
    "            x = F.softmax(self.fc2(x), dim=0)\n",
    "            x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, memory_size, keys):\n",
    "        self.memory = {}\n",
    "        for key in keys:\n",
    "            self.memory[key] = collections.deque(maxlen=memory_size)\n",
    "        self.memory_size = memory_size\n",
    "\n",
    "    def save(self, observations):\n",
    "        for i, key in enumerate(self.memory.keys()):\n",
    "            self.memory[key].append(observations[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory['x'])\n",
    "\n",
    "    def sample(self, idx):\n",
    "        sub_memory = {}\n",
    "        for key in self.memory.keys():\n",
    "            sub_memory[key] = [self.memory[key][i] for i in idx]\n",
    "\n",
    "        ss, actions, rs, ss_next, dones = sub_memory.values()\n",
    "        ss = torch.stack(ss)\n",
    "        ss_next = torch.stack(ss_next)\n",
    "        rs = np.array(rs)\n",
    "        rs = torch.from_numpy(rs).float()\n",
    "\n",
    "        return (ss, actions, rs, ss_next, dones)\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        date_time = datetime.datetime.now().strftime(\"%Y%m%d-%H_%M_%S\")\n",
    "        self.parser = Json_Parser(\"config.json\")\n",
    "        self.parm = self.parser.load_parser()\n",
    "        self.method = self.parm['method']\n",
    "        self.max_step = self.parm['max_step']\n",
    "        self.discount_factor = self.parm['agent']['discount_factor']\n",
    "        self.lr = self.parm['optimizer']['learning_rate']\n",
    "        self.eps = self.parm['optimizer']['eps']\n",
    "        self.eps_max = self.eps\n",
    "        self.eps_min = self.parm['optimizer']['eps_min']\n",
    "        self.eps_mid = self.parm['optimizer']['eps_mid']\n",
    "        self.eps_anneal = self.parm['optimizer']['eps_anneal']\n",
    "        self.episode_size = self.parm['episode_size']\n",
    "        self.minibatch_size = self.parm['minibatch_size']\n",
    "        self.net_update_period = self.parm['net_update_period']\n",
    "\n",
    "        self.env = gym.make('{}'.format(self.parm['env_name']))\n",
    "        self.net = Qnet()\n",
    "        self.target_net = Qnet()\n",
    "        self.target_net.load_state_dict(self.net.state_dict())\n",
    "        self.target_net.eval()\n",
    "\n",
    "        self.replay_memory = ReplayMemory(self.parm['memory_size'], keys=[\n",
    "                                          'x', 'a', 'r', 'x_next', 'done'])\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.net.parameters(), lr=self.lr, weight_decay=0)\n",
    "        self.loss = nn.SmoothL1Loss()\n",
    "\n",
    "        save_name = self.parm['env_name'] + '_' + self.method + '_' + self.parm['agent']['activation'] + '_' + \\\n",
    "            str(self.parm['agent']['hidden_unit']) + '_' +'surgery_' + date_time\n",
    "        self.writer = SummaryWriter('./result/tensorboard/' + save_name)\n",
    "        self.net_save_path = './result/model/model_{}.pth'.format(save_name)\n",
    "        self.writer.add_text('config', json.dumps(self.parm))\n",
    "\n",
    "    def get_action(self, x):\n",
    "        if np.random.rand() < self.eps:\n",
    "            action = np.random.randint(2)\n",
    "        else:\n",
    "            self.net.eval()\n",
    "            q = self.net(x.view(1, -1))\n",
    "            action = np.argmax(q.detach().numpy())\n",
    "        return action\n",
    "\n",
    "    def epsilon_decaying(self):\n",
    "        if self.eps > self.eps_mid:\n",
    "            self.eps -= (self.eps_max-self.eps_mid)/self.eps_anneal\n",
    "        if self.eps < self.eps_mid and self.eps > self.eps_min:\n",
    "            self.eps -= (self.eps_mid-self.eps_min)/self.eps_anneal\n",
    "\n",
    "    def train(self, running_loss):\n",
    "        self.epsilon_decaying()\n",
    "\n",
    "        self.net.train()\n",
    "        minibatch_idx = np.random.choice(self.replay_memory.__len__(), self.minibatch_size)\n",
    "        ss, actions, rs, ss_next, dones = self.replay_memory.sample(minibatch_idx)\n",
    "        final_state_idx = np.nonzero(dones)\n",
    "\n",
    "        if self.method == \"double\":\n",
    "            with torch.no_grad():\n",
    "                self.net.eval()\n",
    "                q_next = self.net(ss_next)\n",
    "                q_next_ = self.target_net(ss_next)\n",
    "\n",
    "            self.net.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            q = self.net(ss)\n",
    "            q_next_max, q_next_argmax = torch.max(q_next, 1)\n",
    "            v_next = torch.gather(q_next_, 1, q_next_argmax.view(-1, 1)).squeeze()\n",
    "\n",
    "        if self.method == \"vanilla\":\n",
    "            with torch.no_grad():\n",
    "                q_next = self.target_net(ss_next)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            q = self.net(ss)\n",
    "            q_next_max, q_next_argmax = torch.max(q_next, 1)\n",
    "            v_next = q_next_max\n",
    "\n",
    "        v_next[final_state_idx] = 0\n",
    "        q_target = rs + self.discount_factor*v_next\n",
    "        actions = torch.tensor(actions).view(-1, 1)\n",
    "        q_relevant = torch.gather(q, 1, actions).squeeze()\n",
    "\n",
    "        loss = self.loss(q_relevant, q_target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        running_loss = loss.item() if running_loss == 0 else 0.99 * \\\n",
    "            running_loss + 0.01*loss.item()\n",
    "\n",
    "        return running_loss\n",
    "\n",
    "    def surgery(self, old_link, new_link, old_para):\n",
    "        '''\n",
    "        do surgery for each layer, \n",
    "        simply use zero_init for new weight. \n",
    "        '''\n",
    "        for name, g in self.net.named_parameters():\n",
    "            if g.shape == old_para[name].shape:\n",
    "                g.data = old_para[name].data\n",
    "            else:\n",
    "                new_g = torch.zeros_like(g)\n",
    "                mid_channel, in_channel = old_para[name].shape\n",
    "                for old_feature in old_link:\n",
    "                    new_g[:mid_channel, new_link[old_feature]] = \\\n",
    "                        old_para[name][:, old_link[old_feature]]\n",
    "                g.data = new_g\n",
    "        self.target_net.load_state_dict(self.net.state_dict())\n",
    "        self.eps_surgery = self.parm['optimizer']['eps_surgery']\n",
    "        self.eps = self.eps_surgery\n",
    "        # self.eps_anneal_surgery = self.parm['optimizer']['eps_anneal_surgery']\n",
    "        \n",
    "    def sample_with_surgery(self, sample_n=10000, show=False):\n",
    "        '''\n",
    "        Test performace after Surgery. \n",
    "        To check if performace is kept after Surgery.\n",
    "        '''\n",
    "        score = 0\n",
    "        temp_eps = self.eps\n",
    "        self.eps = 0\n",
    "        for episode in range(sample_n):\n",
    "            s_now = self.env.reset()\n",
    "            s_prev = s_now\n",
    "            for step in range(self.max_step):\n",
    "                x = torch.from_numpy(np.concatenate(\n",
    "                    (s_now, s_now-s_prev))).float()\n",
    "                a = self.get_action(x)\n",
    "                s_next, r, done, _ = self.env.step(a)\n",
    "                score += 1\n",
    "                x_next = torch.from_numpy(\n",
    "                    np.concatenate((s_next, s_next-s_now))).float()\n",
    "                self.replay_memory.save((x, a, r, x_next, done))\n",
    "                if done:\n",
    "                    break\n",
    "                else:\n",
    "                    s_prev = s_now\n",
    "                    s_now = s_next\n",
    "            if show: \n",
    "                print(\"sample episode: {} | score: {:3.1f}\".format(episode, score))\n",
    "            score = 0\n",
    "        self.eps = temp_eps\n",
    "\n",
    "    def run(self):\n",
    "        backprops_total = 0\n",
    "        running_loss = 0\n",
    "        latest_scores = collections.deque(maxlen=100)\n",
    "        pass_score = self.max_step - 4\n",
    "\n",
    "        s_now = self.env.reset()\n",
    "        s_prev = s_now\n",
    "        score = 0\n",
    "        terminal_flag = False\n",
    "\n",
    "        for episode in range(self.episode_size):\n",
    "            episode += 1\n",
    "            for step in range(self.max_step):\n",
    "                x = torch.from_numpy(np.concatenate(\n",
    "                    (s_now, s_now-s_prev))).float()\n",
    "                a = self.get_action(x)\n",
    "\n",
    "                s_next, r, done, _ = self.env.step(a)\n",
    "                score += 1\n",
    "\n",
    "                x_next = torch.from_numpy(\n",
    "                    np.concatenate((s_next, s_next-s_now))).float()\n",
    "                self.replay_memory.save((x, a, r, x_next, done))\n",
    "\n",
    "                if done:\n",
    "                    latest_scores.append(score)\n",
    "                    score = 0\n",
    "                    s_now = self.env.reset()\n",
    "                    s_prev = s_now\n",
    "                else:\n",
    "                    s_prev = s_now\n",
    "                    s_now = s_next\n",
    "\n",
    "                if self.replay_memory.__len__() > self.minibatch_size:\n",
    "                    running_loss = self.train(running_loss)\n",
    "                    backprops_total += 1\n",
    "\n",
    "                self.writer.add_scalar('memory_size', self.replay_memory.__len__(), episode)\n",
    "                self.writer.add_scalar('epsilon', self.eps, episode)\n",
    "                self.writer.add_scalar('running_loss', running_loss, episode)\n",
    "                self.writer.add_scalar('avg_score', np.mean(latest_scores), episode)\n",
    "\n",
    "                if backprops_total % self.net_update_period == 0:\n",
    "                    self.target_net.load_state_dict(self.net.state_dict())\n",
    "\n",
    "                if done and episode % 100 == 0:\n",
    "                    print(\"episode: {} | memory_size: {:5d} | eps: {:.3f} | running_loss: {:.3f} | last 100 avg score: {:3.1f}\".\n",
    "                          format(episode, self.replay_memory.__len__(), self.eps, running_loss, np.mean(latest_scores)))\n",
    "                    torch.save(self.net.state_dict(), self.net_save_path)\n",
    "\n",
    "                    if np.mean(latest_scores) > pass_score:\n",
    "                        print('Latest 100 average score: {}, pass score: {}, test is passed'.format(\n",
    "                            np.mean(latest_scores), pass_score))\n",
    "                        terminal_flag = True\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "            if terminal_flag:\n",
    "                break\n",
    "        self.env.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "agent = DQNAgent()\n",
    "old = torch.load('/home/workspace/util/surgery/CartPole_DQN/result/model/model_CartPole-v0_double_relu_256_in220220516-09_55_43.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "old_link = {\"Cart Position\":0, \"Pole Angle\":1, \"Cart Position_d\":2, \"Pole Angle_d\":3, }\n",
    "new_link = {\"Cart Position\":0, \"Cart Velocity\":1, \"Pole Angle\":2, \"Pole Angular Velocity\":3, \n",
    "    \"Cart Position_d\":4, \"Cart Velocity_d\":5, \"Pole Angle_d\":6, \"Pole Angular Velocity_d\":7}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "agent.surgery(old_link, new_link, old)\n",
    "agent.sample_with_surgery(15, show=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sample episode: 0 | score: 199.0\n",
      "sample episode: 1 | score: 199.0\n",
      "sample episode: 2 | score: 199.0\n",
      "sample episode: 3 | score: 199.0\n",
      "sample episode: 4 | score: 199.0\n",
      "sample episode: 5 | score: 199.0\n",
      "sample episode: 6 | score: 199.0\n",
      "sample episode: 7 | score: 199.0\n",
      "sample episode: 8 | score: 199.0\n",
      "sample episode: 9 | score: 199.0\n",
      "sample episode: 10 | score: 199.0\n",
      "sample episode: 11 | score: 199.0\n",
      "sample episode: 12 | score: 199.0\n",
      "sample episode: 13 | score: 199.0\n",
      "sample episode: 14 | score: 199.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "agent.replay_memory.__len__(), agent.eps_surgery"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2985, 0.25)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "agent.run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/miniconda/envs/tftorch/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "episode: 100 | memory_size: 11979 | eps: 0.088 | running_loss: 0.607 | last 100 avg score: 107.1\n",
      "episode: 200 | memory_size: 21979 | eps: 0.058 | running_loss: 0.524 | last 100 avg score: 166.7\n",
      "episode: 300 | memory_size: 31979 | eps: 0.028 | running_loss: 0.530 | last 100 avg score: 200.0\n",
      "Latest 100 average score: 200.0, pass score: 195, test is passed\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "for name ,g in agent.net.named_parameters():\n",
    "    print(name, g[:10, ])\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fc1.weight tensor([[-7.3905e-01, -1.1381e-01,  1.7621e-02, -7.5021e-02,  4.4969e-02,\n",
      "          2.4720e-02,  2.0213e-01, -3.1201e-02],\n",
      "        [ 8.9196e-02,  0.0000e+00, -3.1708e-01,  0.0000e+00, -4.6932e-01,\n",
      "          0.0000e+00,  2.5036e-01,  0.0000e+00],\n",
      "        [ 4.6823e-01,  1.0666e-02, -3.4330e-01, -8.2394e-03,  1.0487e+00,\n",
      "          1.1871e-02, -8.7368e-01, -7.6681e-03],\n",
      "        [-7.6476e-01, -1.3465e-01, -2.9084e-01, -1.3447e-01, -7.6827e-01,\n",
      "         -1.1589e-02, -8.3233e-01,  6.1097e-03],\n",
      "        [-1.3532e-01, -1.2255e-01, -6.3762e-01, -8.3289e-02,  4.8578e-01,\n",
      "          3.0598e-02, -2.1476e+00, -3.1516e-02],\n",
      "        [-3.4078e-01, -5.0454e-02, -2.3279e-01,  1.3385e-02, -4.2977e-01,\n",
      "         -2.3186e-02,  1.3525e+00,  1.9072e-02],\n",
      "        [-7.4251e-02,  6.8741e-03,  5.4974e-01,  2.4864e-02,  3.8359e-01,\n",
      "         -9.5824e-03,  1.4494e+00,  1.4727e-02],\n",
      "        [ 3.2487e-01,  4.9868e-02,  2.8924e-01, -6.7122e-04,  4.6704e-02,\n",
      "         -3.3893e-02, -3.8517e-01,  3.2998e-02],\n",
      "        [-5.8798e-03,  0.0000e+00, -2.8985e-01,  0.0000e+00, -4.3765e-01,\n",
      "          0.0000e+00,  2.4986e-01,  0.0000e+00],\n",
      "        [-5.3203e-01, -7.5061e-02, -5.3588e-02,  6.6005e-03,  9.4865e-02,\n",
      "         -3.5248e-03,  7.0131e-01,  1.0421e-03]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tftorch': conda)"
  },
  "interpreter": {
   "hash": "3242c50314a9a68f934114b03bfda27d4d4439c8399dcbb46cdc3239617c61c1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}